{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6PrYqhHXmduj",
        "outputId": "ee9dd15e-1a12-48eb-ef5b-96c38ddec0f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚è≥ Installing libraries... (This takes ~45 seconds)\n"
          ]
        }
      ],
      "source": [
        "# @title üöÄ Launch Final App (Matched to Turbocharged Training)\n",
        "import os\n",
        "import time\n",
        "import subprocess\n",
        "import re\n",
        "\n",
        "# --- INSTALL REQUIREMENTS ---\n",
        "print(\"‚è≥ Installing libraries...\")\n",
        "!pip install -q streamlit open_clip_torch transformers joblib scikit-learn opencv-python-headless matplotlib peft pandas\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n9VFpE5mKwP0",
        "outputId": "d6770992-9c43-45e8-8b2c-be850c8319b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚è≥ Installing libraries...\n",
            "‚òÅÔ∏è Setting up Cloudflare Tunnel...\n",
            "üöÄ Restarting Streamlit...\n",
            "üîó Opening Tunnel...\n",
            "\n",
            "üëâ \u001b[96mCLICK HERE: https://tear-decimal-bradford-millennium.trycloudflare.com\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "print(\"‚òÅÔ∏è Setting up Cloudflare Tunnel...\")\n",
        "!wget -q -nc https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64\n",
        "!chmod +x cloudflared-linux-amd64\n",
        "\n",
        "# --- WRITE THE APP ---\n",
        "with open(\"app.py\", \"w\") as f:\n",
        "    f.write('''\n",
        "import streamlit as st\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import open_clip\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from peft import LoraConfig, get_peft_model\n",
        "\n",
        "# --- PAGE CONFIG ---\n",
        "st.set_page_config(page_title=\"Derma-Semantics Pro\", layout=\"wide\", page_icon=\"üß¨\")\n",
        "\n",
        "st.title(\"üß¨ Derma-Semantics Pro: Specialized Diagnostic\")\n",
        "st.markdown(\"\"\"\n",
        "**System Status:** ‚úÖ Loaded \"Turbocharged\" Contrastive Model (Rank 32)\n",
        "\"\"\")\n",
        "\n",
        "# --- 1. LOAD SYSTEM (SPECIALIZED CONTRASTIVE MODEL) ---\n",
        "@st.cache_resource\n",
        "def load_system():\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "    # A. Load Base BioMedCLIP Structure\n",
        "    print(\"‚è≥ Loading BioMedCLIP Base...\")\n",
        "    model, _, preprocess = open_clip.create_model_and_transforms('hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224')\n",
        "    tokenizer = open_clip.get_tokenizer('hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224')\n",
        "\n",
        "    model.to(device)\n",
        "\n",
        "    # B. Inject LoRA Layers (Re-creating the architecture from training)\n",
        "    def get_linear_layer_names(module):\n",
        "        target_names = set()\n",
        "        for name, mod in module.named_modules():\n",
        "            if isinstance(mod, torch.nn.Linear):\n",
        "                target_names.add(name.split('.')[-1])\n",
        "        return list(target_names)\n",
        "\n",
        "    # 1. Apply to Vision\n",
        "    vision_targets = get_linear_layer_names(model.visual)\n",
        "\n",
        "    # === CRITICAL UPDATE: MATCH TRAINING CONFIG ===\n",
        "    # r=32, lora_alpha=64 (Matches Option G Training)\n",
        "    config_vision = LoraConfig(r=32, lora_alpha=64, target_modules=vision_targets, lora_dropout=0.1, bias=\"none\")\n",
        "    model.visual = get_peft_model(model.visual, config_vision)\n",
        "\n",
        "    # 2. Text Encoder was unfrozen during training (state_dict handles the weights)\n",
        "\n",
        "    # C. Load Your New Specialized Weights\n",
        "    # weights_path = \"/content/drive/MyDrive/Colab Notebooks/biomedclip_balanced_best.pt\"\n",
        "    # weights_path = \"/content/drive/MyDrive/Colab Notebooks/biomedclip_contrastive_finetuned (1).pt\"\n",
        "    weights_path = \"/content/drive/MyDrive/Colab Notebooks/biomedclip_balanced_best2.pt\"\n",
        "    try:\n",
        "        if os.path.exists(weights_path):\n",
        "            print(\"üìÇ Loading Specialized Contrastive Weights...\")\n",
        "            checkpoint = torch.load(weights_path, map_location=device)\n",
        "\n",
        "            # Handle state_dict key structure\n",
        "            sd = checkpoint['model_state_dict'] if 'model_state_dict' in checkpoint else checkpoint\n",
        "\n",
        "            # Load weights (strict=False because CLIP has some unused parameters sometimes)\n",
        "            msg = model.load_state_dict(sd, strict=False)\n",
        "            print(f\"‚úÖ Weights Loaded! (Missing keys expected for frozen parts: {len(msg.missing_keys)})\")\n",
        "        else:\n",
        "            st.warning(\"‚ö†Ô∏è Fine-tuned weights not found. Using generic BioMedCLIP (Results will be less accurate).\")\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error loading weights: {e}\")\n",
        "\n",
        "    model.eval()\n",
        "    return model, preprocess, tokenizer, device\n",
        "\n",
        "model, preprocess, tokenizer, device = load_system()\n",
        "\n",
        "# --- 2. DYNAMIC SALIENCY FUNCTION ---\n",
        "def get_saliency_map(image, model, preprocess, tokenizer, device, target_text):\n",
        "    model.eval()\n",
        "\n",
        "    img_input = preprocess(image).unsqueeze(0).to(device)\n",
        "    img_input.requires_grad_() # Track gradients\n",
        "\n",
        "    text_input = tokenizer([target_text]).to(device)\n",
        "\n",
        "    # Forward Pass\n",
        "    image_features = model.encode_image(img_input)\n",
        "    text_features = model.encode_text(text_input)\n",
        "\n",
        "    # Normalize\n",
        "    image_features = image_features / image_features.norm(dim=-1, keepdim=True)\n",
        "    text_features = text_features / text_features.norm(dim=-1, keepdim=True)\n",
        "\n",
        "    # Similarity & Backward\n",
        "    similarity = (image_features @ text_features.T)[0, 0]\n",
        "    model.zero_grad()\n",
        "    similarity.backward()\n",
        "\n",
        "    # Gradients\n",
        "    gradients = img_input.grad.data.cpu().numpy()[0]\n",
        "    saliency = np.max(np.abs(gradients), axis=0)\n",
        "    saliency = (saliency - saliency.min()) / (saliency.max() - saliency.min())\n",
        "\n",
        "    return saliency, similarity.item()\n",
        "\n",
        "def plot_heatmap_overlay(original_image, heatmap):\n",
        "    heatmap_resized = cv2.resize(heatmap, (original_image.size[0], original_image.size[1]))\n",
        "    heatmap_colored = plt.cm.jet(heatmap_resized)[:, :, :3]\n",
        "    overlay = np.array(original_image) / 255.0 * 0.6 + heatmap_colored * 0.4\n",
        "\n",
        "    fig, ax = plt.subplots(1, 3, figsize=(12, 4))\n",
        "    ax[0].imshow(original_image); ax[0].set_title(\"Original\"); ax[0].axis('off')\n",
        "    ax[1].imshow(heatmap_resized, cmap='jet'); ax[1].set_title(\"AI Attention\"); ax[1].axis('off')\n",
        "    ax[2].imshow(overlay); ax[2].set_title(\"Overlay\"); ax[2].axis('off')\n",
        "    return fig\n",
        "\n",
        "# --- 3. MAIN UI ---\n",
        "col1, col2 = st.columns([1, 1.5])\n",
        "\n",
        "# DEFINING THE 7 CLASSES (Must match your training logic)\n",
        "isic_classes = {\n",
        "    \"Melanoma (Cancer)\": \"High risk melanoma skin cancer\",\n",
        "    \"Basal Cell Carcinoma (Cancer)\": \"Basal cell carcinoma skin cancer\",\n",
        "    \"Actinic Keratosis (Pre-Cancer)\": \"Actinic keratosis pre-cancerous lesion\",\n",
        "    \"Melanocytic Nevus (Benign)\": \"Benign melanocytic nevus mole\",\n",
        "    \"Benign Keratosis (Benign)\": \"Benign keratosis-like lesion\",\n",
        "    \"Dermatofibroma (Benign)\": \"Benign dermatofibroma skin lesion\",\n",
        "    \"Vascular Lesion (Benign)\": \"Benign vascular skin lesion\"\n",
        "}\n",
        "\n",
        "# Define which are \"Bad\" for the summary risk alert\n",
        "malignant_keys = [\"Melanoma (Cancer)\", \"Basal Cell Carcinoma (Cancer)\", \"Actinic Keratosis (Pre-Cancer)\"]\n",
        "\n",
        "with col1:\n",
        "    st.subheader(\"1. Patient Input\")\n",
        "    uploaded_file = st.file_uploader(\"Upload Image\", type=[\"jpg\", \"png\", \"jpeg\"])\n",
        "\n",
        "    if uploaded_file:\n",
        "        image = Image.open(uploaded_file).convert(\"RGB\")\n",
        "        st.image(image, caption=\"Clinical View\", use_column_width=True)\n",
        "\n",
        "with col2:\n",
        "    st.subheader(\"2. AI Analysis\")\n",
        "\n",
        "    if uploaded_file and st.button(\"Run Diagnostic\"):\n",
        "        with st.spinner(\"Analyzing Lesion Pattern...\"):\n",
        "\n",
        "            # A. SEMANTIC PROFILE (Zero-Shot Classification)\n",
        "            img_tensor = preprocess(image).unsqueeze(0).to(device)\n",
        "            sim_scores = {}\n",
        "\n",
        "            with torch.no_grad():\n",
        "                img_feat = model.encode_image(img_tensor)\n",
        "                img_feat /= img_feat.norm(dim=-1, keepdim=True)\n",
        "\n",
        "                for label, prompt in isic_classes.items():\n",
        "                    txt = tokenizer([prompt]).to(device)\n",
        "                    txt_feat = model.encode_text(txt)\n",
        "                    txt_feat /= txt_feat.norm(dim=-1, keepdim=True)\n",
        "                    score = (img_feat @ txt_feat.T).item()\n",
        "                    sim_scores[label] = score\n",
        "\n",
        "            # Sort Results\n",
        "            df_scores = pd.DataFrame(list(sim_scores.items()), columns=[\"Condition\", \"Score\"])\n",
        "            df_scores = df_scores.sort_values(by=\"Score\", ascending=False)\n",
        "            top_condition = df_scores.iloc[0][\"Condition\"]\n",
        "\n",
        "            # B. DIAGNOSTIC SUMMARY\n",
        "            st.divider()\n",
        "            if top_condition in malignant_keys:\n",
        "                 st.error(f\"**Primary Diagnosis: {top_condition}**\")\n",
        "                 st.caption(\"‚ö†Ô∏è The model detected patterns consistent with malignancy.\")\n",
        "            else:\n",
        "                 st.success(f\"**Primary Diagnosis: {top_condition}**\")\n",
        "                 st.caption(\"‚úÖ The model detected patterns consistent with benign lesions.\")\n",
        "\n",
        "            # C. BAR CHART\n",
        "            st.markdown(\"### üìä Semantic Similarity Profile\")\n",
        "            st.caption(\"Match confidence for each specific condition:\")\n",
        "            st.bar_chart(df_scores.set_index(\"Condition\"))\n",
        "\n",
        "            # D. DYNAMIC X-RAY\n",
        "            st.divider()\n",
        "            st.markdown(\"### üëÅÔ∏è Dynamic X-Ray Vision\")\n",
        "\n",
        "            # Selectbox defaults to the top prediction\n",
        "            target_class = st.selectbox(\"Show features for:\", list(isic_classes.keys()), index=list(isic_classes.keys()).index(top_condition))\n",
        "            target_prompt = isic_classes[target_class]\n",
        "\n",
        "            with st.spinner(f\"Generating heatmap for '{target_class}'...\"):\n",
        "                try:\n",
        "                    heatmap, score = get_saliency_map(image, model, preprocess, tokenizer, device, target_prompt)\n",
        "                    fig = plot_heatmap_overlay(image, heatmap)\n",
        "                    st.pyplot(fig)\n",
        "                    st.info(f\"Visualizing pixels that match description: **'{target_prompt}'**\")\n",
        "                except Exception as e:\n",
        "                    st.error(f\"Error: {e}\")\n",
        "\n",
        "''')\n",
        "\n",
        "# --- LAUNCH ---\n",
        "print(\"üöÄ Restarting Streamlit...\")\n",
        "!pkill -f streamlit\n",
        "time.sleep(2)\n",
        "subprocess.Popen([\"streamlit\", \"run\", \"app.py\", \"--server.port\", \"8501\", \"--server.address\", \"0.0.0.0\"])\n",
        "\n",
        "print(\"üîó Opening Tunnel...\")\n",
        "with open(\"cf_logs.txt\", \"w\") as log_file:\n",
        "    subprocess.Popen([\"./cloudflared-linux-amd64\", \"tunnel\", \"--url\", \"http://localhost:8501\"], stdout=log_file, stderr=log_file)\n",
        "\n",
        "time.sleep(10)\n",
        "found_url = None\n",
        "for i in range(10):\n",
        "    if os.path.exists(\"cf_logs.txt\"):\n",
        "        with open(\"cf_logs.txt\", \"r\") as f:\n",
        "            content = f.read()\n",
        "            match = re.search(r\"https://[a-zA-Z0-9-]+\\.trycloudflare\\.com\", content)\n",
        "            if match:\n",
        "                found_url = match.group(0)\n",
        "                break\n",
        "    time.sleep(2)\n",
        "\n",
        "if found_url:\n",
        "    print(f\"\\nüëâ \\033[96mCLICK HERE: {found_url}\\033[0m\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
